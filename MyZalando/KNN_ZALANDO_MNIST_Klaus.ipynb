{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN für die Zalando-Artikel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca. 60000 Fotos von Zalando-Artikeln wurden als Graustufenbild mit einer Auflösung von 28x28 bereitgestellt. dabei handelt es sich um Zalando-Waren, die gelabelt sind in 10 Kategorien.\n",
    "\n",
    "Mit diesen Daten wird hier ein 3-stufiges KNN trainiert.\n",
    "\n",
    "Das KNN hat also:\n",
    "- 28x28 = 784 Input-Neuronen\n",
    "- 10 Output-Neuronen\n",
    "- sowie eine verdeckte Schicht mit einer per Parameter steuerbaren Anzahl Neuronen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der notwendigen Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# scipy.special for the sigmoid function expit()\n",
    "from scipy.special import expit \n",
    "\n",
    "# helper to load data from PNG image files\n",
    "# glob helps select multiple files using patterns\n",
    "import glob\n",
    "\n",
    "# library for plotting arraysimport imageio\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# library for plotting\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namen der Kleidungstypen festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelle = {0:\"T-shirt\", \n",
    "           1:\"Hose\", \n",
    "           2:\"Pullover\",\n",
    "           3:\"Kleid\",\n",
    "           4:\"Jacke\",\n",
    "           5:\"Sandale\",\n",
    "           6:\"Hemd\",\n",
    "           7:\"Sneaker\",\n",
    "           8:\"Tasche\",\n",
    "           9:\"Stiefel\"\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Klasse für ein neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-schichtiges Neuronales Netz**\n",
    "\n",
    "Parameter:\n",
    "- Anzahl Neuronen des Input Layer\n",
    "- Anzahl Neuronen des Hidden Layer\n",
    "- Anzahl Neuronen des Output-Layer\n",
    "- Lernrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setzen und KNN aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input-, hidden- and output-nodes nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "knn = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsdaten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_image_file = open(\"data/X_train.csv\", 'r')\n",
    "training_image_list = training_image_file.readlines()\n",
    "training_image_file.close()\n",
    "\n",
    "training_typen_file = open(\"data/y_train.csv\", 'r')\n",
    "training_typen_list = training_typen_file.readlines()\n",
    "training_typen_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "print (\"Bitte warten!\")\n",
    "for e in range(epochs):\n",
    "    print(e+1, \"von\", epochs, \"Epochen gestartet.... \", end = \"\")\n",
    "    # go through all records in the training data set\n",
    "    for index in range(60000):\n",
    "        # split the record by the ',' commas\n",
    "        all_values = training_image_list[index].split(\",\")\n",
    "        # scale and shift the inputs\n",
    "        inputs = (np.asfarray(all_values) / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(training_typen_list[index])] = 0.99\n",
    "        knn.train(inputs, targets)\n",
    "        pass\n",
    "    print (\"done\")\n",
    "    pass\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool zum Testen der Qualität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soll_ist (index, image_list, typen_list):\n",
    "    img_array = np.asfarray(image_list[index].split(\",\")).astype(int)\n",
    "    img_data  = 255.0 - img_array\n",
    "    img_data  = img_array\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    inputs = img_data\n",
    "\n",
    "    # query the network\n",
    "    outputs = knn.query(inputs)\n",
    "    label = np.argmax(outputs)\n",
    "    correct_label = int(typen_list[index])\n",
    "    return (correct_label, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soll_ist(42,training_image_list, training_typen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soll_ist_all(image_list, typen_list):\n",
    "    m = np.zeros((10, 10), dtype = int)\n",
    "    anzahl = len(image_list)\n",
    "    for index in range (anzahl):\n",
    "        s, i = soll_ist (index, image_list, typen_list)\n",
    "        m [s][i] += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_training = soll_ist_all (training_image_list, training_typen_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Güte des KNN mit den Trainingsdaten(!) testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_all_traindata():\n",
    "    korrekte = 0\n",
    "    anzahl = len(training_image_list)\n",
    "    falsch = {x: 0 for x in modelle.values()}\n",
    "    wrongIndizes = []\n",
    "    \n",
    "    for index in range (anzahl):\n",
    "        \n",
    "        img_array = np.asfarray(training_image_list[index].split(\",\")).astype(int)\n",
    "        img_data  = img_array\n",
    "        img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # data is remaining values\n",
    "        inputs = img_data\n",
    "\n",
    "        # query the network\n",
    "        outputs = knn.query(inputs)\n",
    "        \n",
    "        # the index of the highest value corresponds to the label\n",
    "        label = np.argmax(outputs)\n",
    "        correct_label = int(training_typen_list[index])\n",
    " \n",
    "        if (label == correct_label):\n",
    "            korrekte += 1\n",
    "        else:\n",
    "            zeile = \"\"\n",
    "            zeile += f'Nr. {index:5} Netz sagt: {label:2} Soll: {correct_label:2}'\n",
    "            falsch[modelle[correct_label]] += 1\n",
    "            wrongIndizes.append(index)\n",
    "    print (\"Falsch erkannt:\")\n",
    "    for f in falsch:\n",
    "        print (f + \": \" + str(falsch[f]))\n",
    "    print (\"Von den\", anzahl, \"Testdaten sind\", korrekte, \"korrekt\", anzahl - korrekte, \"falsch zugeordnet\")\n",
    "    # print(wrongIndizes)\n",
    "    \n",
    "test_all_traindata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=sia_training)\n",
    "df = df.rename(modelle, axis='columns')\n",
    "df = df.rename(modelle, axis='rows')\n",
    "df[\"Fehler\"] = \"\"\n",
    "\n",
    "for i in range (10):\n",
    "    f = 0;\n",
    "    for j in range (10):\n",
    "        if i != j:\n",
    "            inhalt = int (df[modelle[j]][modelle[i]])\n",
    "            f += int (inhalt)\n",
    "    df[\"Fehler\"][modelle[i]] = f\n",
    "\n",
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdaten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "test_image_file = open(\"data/X_test.csv\", 'r')\n",
    "test_image_list = test_image_file.readlines()\n",
    "test_image_file.close()\n",
    "\n",
    "test_typen_file = open(\"data/y_test.csv\", 'r')\n",
    "test_typen_list = test_typen_file.readlines()\n",
    "test_typen_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion zum Testen eines Test-Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testen (index):\n",
    "    #img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    img_array = np.asfarray(test_image_list[index].split(\",\")).astype(int)\n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    #img_data  = 255.0 - img_array\n",
    "    img_data  = img_array\n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    #print(numpy.min(img_data))\n",
    "    #print(numpy.max(img_data))\n",
    "        \n",
    "    # plot image\n",
    "    matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "    # data is remaining values\n",
    "    inputs = img_data\n",
    "\n",
    "    # query the network\n",
    "    outputs = knn.query(inputs)\n",
    "    for i in range (output_nodes):\n",
    "        print (f'Güte der Erkennung {outputs[i][0]:1.5f} : {modelle[i]}')\n",
    "        \n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    correct_label = int(test_typen_list[index])\n",
    "    print(\"should be\", correct_label, \"(\", modelle[correct_label],\")\")\n",
    "    print(\"network says \", label, \"(\", modelle[label],\")\")\n",
    "\n",
    "\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        print (\"match!\")\n",
    "    else:\n",
    "        print (\"no match!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdaten-Güte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_testdaten = soll_ist_all (test_image_list, test_typen_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Tabelle sind die Fehler aufgelistet.\n",
    "\n",
    "- Steht z.B. in der \"Pullover\"-Zeile der Wert 17 in der \"Tasche\"-Spalte, wurden also 17 Pullover fälschlicherweise als Tasche erkannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=sia_testdaten)\n",
    "df = df.rename(modelle, axis='columns')\n",
    "df = df.rename(modelle, axis='rows')\n",
    "df[\"Fehler\"] = \"\"\n",
    "\n",
    "for i in range (10):\n",
    "    f = 0;\n",
    "    for j in range (10):\n",
    "        if i != j:\n",
    "            inhalt = int (df[modelle[j]][modelle[i]])\n",
    "            f += int (inhalt)\n",
    "    df[\"Fehler\"][modelle[i]] = f\n",
    "\n",
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein Testdatensatz wird getestet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testen (42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion, um alle Testdaten zu testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all():\n",
    "    korrekte = 0\n",
    "    log = \"\"\n",
    "    anzahl = len(test_image_list)\n",
    "    falsch = {x: 0 for x in modelle.values()}\n",
    "    wrongIndizes = []\n",
    "    \n",
    "    for index in range (anzahl):\n",
    "        \n",
    "        img_array = np.asfarray(test_image_list[index].split(\",\")).astype(int)\n",
    "        img_data  = img_array\n",
    "        img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # data is remaining values\n",
    "        inputs = img_data\n",
    "\n",
    "        # query the network\n",
    "        outputs = knn.query(inputs)\n",
    "        \n",
    "        # the index of the highest value corresponds to the label\n",
    "        label = np.argmax(outputs)\n",
    "        correct_label = int(test_typen_list[index])\n",
    " \n",
    "        if (label == correct_label):\n",
    "            korrekte += 1\n",
    "        else:\n",
    "            zeile = \"\"\n",
    "            zeile += f'Nr. {index:5} Netz sagt: {label:2} Soll: {correct_label:2}'\n",
    "            log += zeile + \"\\n\"\n",
    "            falsch[modelle[correct_label]] += 1\n",
    "            wrongIndizes.append(index)\n",
    "    #print (log)\n",
    "    print (\"Falsch erkannt:\")\n",
    "    for f in falsch:\n",
    "        print (f + \": \" + str(falsch[f]))\n",
    "    print (\"Von den\", anzahl, \"Testdaten sind\", korrekte, \"korrekt\", anzahl - korrekte, \"falsch zugeordnet\")\n",
    "    # print(wrongIndizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Inhalt",
   "title_sidebar": "Inhalt",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
